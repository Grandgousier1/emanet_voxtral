
#!/usr/bin/env python3
"""
Outil de v√©rification de l'empreinte VRAM d'un mod√®le.

Ce script charge un mod√®le Hugging Face sp√©cifi√©, le d√©place sur le GPU
et mesure la m√©moire VRAM allou√©e. C'est une √©tape de validation cruciale
pour s'assurer qu'un mod√®le peut √™tre charg√© avant de lancer une application compl√®te.

Usage: python check_model_vram.py --model_id <ID_du_mod√®le_huggingface>
"""
import torch
import argparse
import sys
from transformers import AutoModelForCausalLM, AutoConfig

def check_vram(model_id: str):
    print(f"üöÄ D√©marrage de la v√©rification VRAM pour le mod√®le: {model_id}")

    # --- V√©rification 1: Disponibilit√© de CUDA ---
    if not torch.cuda.is_available():
        print("üî•üî•üî• ERREUR: CUDA n'est pas disponible. V√©rification annul√©e.", file=sys.stderr)
        return False

    device = torch.device("cuda")
    print(f"‚úÖ CUDA disponible. P√©riph√©rique: {torch.cuda.get_device_name(0)}")
    print(f"M√©moire totale: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")

    # --- √âtape 2: Chargement du mod√®le ---
    try:
        print(f"--- Chargement du mod√®le '{model_id}' sur le CPU (pour commencer)... ---")
        # Utiliser bfloat16 si support√© pour un chargement plus r√©aliste
        dtype = torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16
        print(f"Utilisation du dtype: {dtype}")
        
        model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=dtype)
        print("‚úÖ Mod√®le charg√© sur le CPU.")

        # --- √âtape 3: Mesure de la VRAM ---
        torch.cuda.empty_cache() # Vider le cache avant la mesure
        initial_memory = torch.cuda.memory_allocated(device)
        
        print(f"--- D√©placement du mod√®le vers {device}... ---")
        model.to(device)
        
        final_memory = torch.cuda.memory_allocated(device)
        torch.cuda.empty_cache()

        vram_usage_gb = (final_memory - initial_memory) / 1e9
        
        print(f"\n{'='*60}\nR√©sultat de la mesure VRAM\n{'='*60}")
        print(f"‚úÖ Empreinte VRAM du mod√®le '{model_id}': {vram_usage_gb:.2f} GB")
        print('='*60)

        return True

    except Exception as e:
        print(f"üî•üî•üî• ERREUR: Une exception est survenue: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="V√©rifie l'utilisation de la VRAM pour un mod√®le Hugging Face.")
    parser.add_argument("--model_id", type=str, required=True, help="L'identifiant du mod√®le sur le Hub Hugging Face (ex: 'meta-llama/Llama-2-7b-chat-hf').")
    args = parser.parse_args()

    if check_vram(args.model_id):
        sys.exit(0)
    else:
        sys.exit(1)
