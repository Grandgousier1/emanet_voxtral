
"""
Test atomique pour l'API d'optimisation B200.

Ce script vÃ©rifie que les fonctions de `utils.b200_optimizer` peuvent Ãªtre
appelÃ©es et exÃ©cutÃ©es sur un modÃ¨le simple avec un tenseur sur le GPU.
Il a pour but de dÃ©tecter rapidement les incompatibilitÃ©s entre PyTorch, le driver
NVIDIA, et le code d'optimisation spÃ©cifique Ã  la B200.

Usage: python test_b200_api_atomic.py
"""
import torch
import sys

def run_test():
    print("ðŸš€ DÃ©marrage du test atomique de l'API B200...")

    # --- VÃ©rification 1: DisponibilitÃ© de CUDA ---
    if not torch.cuda.is_available():
        print("ðŸ”¥ðŸ”¥ðŸ”¥ ERREUR: CUDA n'est pas disponible. Test annulÃ©.", file=sys.stderr)
        return False
    
    device = torch.device("cuda")
    print(f"âœ… CUDA disponible. Utilisation du pÃ©riphÃ©rique: {torch.cuda.get_device_name(0)}")

    # --- VÃ©rification 2: Import de l'optimiseur ---
    try:
        # Note: Assurez-vous que le chemin est correct pour votre structure de projet
        from utils.b200_optimizer import get_b200_optimizer, apply_b200_optimizations
        print("âœ… Les fonctions de l'optimiseur B200 ont Ã©tÃ© importÃ©es avec succÃ¨s.")
    except ImportError as e:
        print(f"ðŸ”¥ðŸ”¥ðŸ”¥ ERREUR: Impossible d'importer depuis utils.b200_optimizer: {e}", file=sys.stderr)
        print("Assurez-vous que le projet est installÃ© en mode Ã©ditable (`pip install -e .`) et que le PYTHONPATH est correct.")
        return False

    # --- VÃ©rification 3: Application de l'optimisation ---
    print("--- CrÃ©ation d'un modÃ¨le et d'un tenseur factices ---")
    try:
        # ModÃ¨le simple
        dummy_model = torch.nn.Sequential(
            torch.nn.Linear(16, 32),
            torch.nn.ReLU(),
            torch.nn.Linear(32, 16)
        ).to(device)
        
        # Tenseur factice
        dummy_tensor = torch.randn(4, 16).to(device)

        print("--- Tentative d'application des optimisations B200 ---")
        # Simule l'obtention de la configuration d'optimisation
        optimizer_config = get_b200_optimizer()
        print(f"Configuration d'optimisation obtenue: {optimizer_config}")

        # Applique les optimisations
        optimized_model = apply_b200_optimizations(dummy_model, optimizer_config)
        print("âœ… La fonction apply_b200_optimizations s'exÃ©cute sans erreur.")

        # ExÃ©cute une passe forward pour s'assurer que le modÃ¨le est toujours fonctionnel
        print("--- ExÃ©cution d'une passe forward sur le modÃ¨le optimisÃ© ---")
        output = optimized_model(dummy_tensor)
        print(f"âœ… Passe forward rÃ©ussie. Shape de sortie: {output.shape}")

    except Exception as e:
        print(f"ðŸ”¥ðŸ”¥ðŸ”¥ ERREUR: Une exception est survenue lors de l'application ou de l'exÃ©cution des optimisations: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        return False

    print("\nâœ…âœ…âœ… Le test atomique de l'API B200 est un succÃ¨s!")
    return True

if __name__ == "__main__":
    if run_test():
        sys.exit(0)
    else:
        sys.exit(1)
